---
layout: post
title: "Functionalism and Panpyschism"
date: 2012-11-26 22:52
comments: true
published: false
categories: [philosophy, philosophy of mind]
---

Panpyschism is a bit of an odd idea. It pops up from time to time, often amongst those with a mostly physicalist bent. Even Russell had a brush with it. The attraction is pretty understandable for a physicalist: it's pretty tough to explain how we can put together a bunch of stuff that is non-experiental and then end up with something that _is_.[^emergence] If, on the other hand, _everything_ is experiental (or at least proto-experiental), then the problem seems more tractable. You still have to explain how full-blown experiences arise from pieces that are also experiental (or proto-experiental), but it sure feels like that ought to be easier.

[^emergence]: Obviously this kind of thing happens all the time; it's not mysterious that we can put together a bunch of things that aren't furniture and end up with something that is. But it seems to be much harder to do this with experience.

I would like to argue that this temptation should be particularly pressing for functionalists.[^strawson] Firstly, a quick functionalism recap. Functionalism claims that what determines whether something is a mental state of a particular kind is the _functional role_ that that state plays. So the state that we label "belief" is a belief because of the complex functional relationships that it has with other mental states and the environment - not, for example, because of any particular kind of internal composition. A particular consequence of this is that mental states are _multiply realizable_, that is, they can be instantiated by many different kinds of "hardware".

[^strawson]: However, I'm not going to be arguing along the lines of, say, Strawson's "Why Physicalism Entails Panpsychism"; he's on a quite different tack, which I don't really agree with.

"Panpsychism", on the other hand, is used in a few ways. Generally it's used to indicate that mind is in some way a widespread and/or fundamental part of the universe. Firstly, I'm going to take "atoms have it" as being a loose proxy for some property being "widespread and fundamental". If we interpret panpsychism as saying that mentality of some kind is a "widespread and fundamental" part of the universe (i.e. atoms have it), then it's pretty clear that this is at least talking about the same kind of stuff as functionalism. If, on the other hand, we interpret it as talking about _conscious experience_, then it's not clear what this has to do with functionalism as stated. However, it seems pretty likely that most functionalists will also have some kind of functional criterion for the presence of conscious experience also


However, it has always been difficult for functionalists to decide what constitutes the _system_ that a mental state must act within. For example, my phone plays a fairly active part in my life -- there is a signal-passing mechanism from my brain to my phone, in which I enter events for it to remember, and then there is a signal-passing mechanism in the opposite direction, when it beeps to remind of an engagement. Information stored in my phone is often not retained in my brain (I forget!), and I tend to trust what it says.[^fallible] From a functionalist perspective, it is hard to see why I should exclude my phone from being a part of my mind. It is, admittedly, accessed over a fairly low-bandwidth and unoptimized connection (my typing events into it), but that hardly seems to impair its _functionality_.[^extended]

[^fallible]: Of course, occasionally it is wrong, but so is one's memory!

[^extended]: Naturally, some philosophers embrace the conclusion that the mind can extend outside the head. See Clark and Chalmers, The Extended Mind. I actually don't think this is a totally crazy idea.

The point here is that functionality is easy to find. It extends in the other direction too. An object like a thermostat exhibits some very basic functionality: it tracks the temperature, and changes state between two options depending on that value. Moreover, it has some of the features that might have been thought to be characteristic of the _kind_ of functionality that is mental. For example, it has something like a "model" of part of the world (it tracks the temperature); it is reactive to outside events in a sensible way; it can even be interpreted as having a "goal" of sorts: to keep the temperature at a certain level. Does this mean that the functionalist ought to ascribe consciousness to a thermostat?

Of course, the functionalist does not have to accept that consciousness is binary. If it is a feature that, say, exists in proportion to some measure of the complexity of the system being considered, then a thermostat might be an example of a "minimally" conscious entity. To steal Chalmers' phrase, perhaps it has "one bit" of consciousness.[^Chalmers] We could maybe even imagine what it is like to be a thermostat: it could be like just being aware of whether it is dark or light.

[^Chalmers]: Chalmers also seems to have panpyschist sympathes, although he's a property dualist rather than a functionalist. See ch.8 of The Conscious Mind, and "What is it like to be a thermostat?".

Accepting that a thermostat has at least "one bit" of consiousness, is not actually panpyschism, although it is closer. Already the picture of the world that is painted is quite different from the usual one. Consciousness (or at least proto-consciousness) is present (albeit in a very limited degree) in many of the complex functional objects that we interact with daily. Computers would be a prime example. The composition problem also seems less daunting: conscious entities are composed of smaller, less complex entities which have correspondingly "less" consciousness, but contribute to the whole.

I actually find this quite a sympathetic idea. Back when I thought Chalmers was right about everything, I took the possibility of panpsychism pretty seriously. I think that the idea that parts of conscious entities could themselves be conscious is not as bizarre as it sounds. For example, if it is sensible to talk about such a thing as the "subconscious"[^sub], then could there not be something that it is like to be one's subconscious? We might even know what it is like: adding bad developmental psychology into the mix, we might suppose that very young infants "mostly" consist of their subconscious, and so that kind of blind infantile reaching for urges might mirror what it is like to be the subconscious of a mature adult.[^strange]

[^sub]: I have a feeling that the subconscious is hazy enough that it may be one of the folk concepts that won't appear in a mature psychology.

[^strange]: Things can get stranger still: what is it like to be the "middle third" of one's brain, say? I think that's still an intelligible question. The answer would be "very strange", as it would involve peculiar internal representations and reactions to the system in which it was embedded, but I don't think it's a wrong question.

But perhaps we can go down even further than the thermostat. Don't _molecules_ enter into some kind of functional relationship with nearby molecules, at least in stable compounds? Does that mean we have to assign them some iota of consciousness? That seems pretty unattractive: surely we can distinguish the kind of functionality that the human brain has (and maybe thermostats do, a little bit), but that atoms do not? The hard part is doing that in a principled way. We can try to say that a molecule doesn't _model_ the world in the way that even a thermostat does... but doesn't it? Come to think of it, how would you even tell whether the molecule was modelling the world?

Okay, so I was cheating a bit when I said that "molecules enter into some kind of functional relationship with nearby molecules". You need to do more than that to establish what's going on functionally. You need to say something about the system and context in which the activity is occurring. That can make a huge difference.

For example, suppose that a molecule's motion is being tracked by some kind of sophisticated camera. At some series of time intervals, it checks how the molecule has moved, and using some kind of complicated look-up-table, it uses that to make a decision on how to play in a game of chess. Let's even suppose that the molecule is moving unimpeded in a straight line. Then is the molecule functioning as a chess computer? Its behaviour is causing the moves to occur in the correct way, after all. Surely not: the work is really being done by the look-up mechanism -- but it is hard to figure out how to say just why this is!

This is pretty much the hardest unsolved problem facing functionalism. At a more macro level, this means that if we interpret the behaviour of a thermostat as acting within some incredibly complex system, then it can look as though the thermostat is simulating Einstein talking to Goedel, which is frankly plenty of mentality for me! There are a number of moves that the functionalist can make[^func], but all I want to highlight here is that _one of them is panpsychism_. All you have to do is bite that big fat bullet and allow that yes, the molecule _is_ just a little bit conscious. (You still need to do some work to show that the molecule isn't a _lot_ conscious, but hey, it's progress.)

[^func]: If you're interested, I think that by far the best thing that's been written on it is in Scott Aaronson's paper "Why Philosophers Should Care About Computational Complexity", along with a positive embarassment of other insights.

I don't think I've done anything like show that you _have_ to be a panpsychist if you're a functionalist, but I'm surprised that it isn't at least more common. Particularly if you're a thermostat-psychist (as I suspect many functionalists secretly are), then it's not so much of a leap to ascribe it to molecules. In the end, I suspect it comes down to how and where we attribute functionality, and that's admittedly a pretty knotty problem.
